{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 提取视频帧\n",
    "\n",
    "extract_frames_from_non_hate_video 函数：\n",
    "从非仇恨视频中提取的帧数由 target_frames 参数决定，默认是 100 帧。\n",
    "如果提取的帧数不足 100 帧，会用白帧填充。\n",
    "\n",
    "extract_frames_from_hate_video 函数：\n",
    "从仇恨视频中提取的帧数也是由 target_frames 参数决定，默认是 100 帧。\n",
    "如果提取的帧数不足 100 帧，会从非仇恨时间段中随机提取帧，或者用白帧填充。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting and saving frames for non-hate videos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Define the function to get video information\n",
    "def get_video_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return None, None\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    return total_frames, fps\n",
    "\n",
    "# Function to check if a frame is near monochrome (all black/white)\n",
    "def is_monochrome(frame: np.ndarray, threshold: int = 15) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the frame is monochrome.\n",
    "    A frame is considered monochrome if the standard deviation of its grayscale pixel values is below a threshold.\n",
    "    \"\"\"\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return np.std(gray_frame) < threshold\n",
    "\n",
    "# Define the function to extract and filter frames from a non-hate video\n",
    "def extract_frames_from_non_hate_video(video_path, target_frames=100):\n",
    "    # Get video info\n",
    "    total_frames, fps = get_video_info(video_path)\n",
    "    if total_frames is None:\n",
    "        return []  # If video info couldn't be retrieved, return an empty list\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Calculate the interval for frame extraction\n",
    "    interval = max(1, total_frames // target_frames)\n",
    "    \n",
    "    # Initialize list to store frames\n",
    "    extracted_frames = []\n",
    "    \n",
    "    # Extract frames\n",
    "    for i in range(0, total_frames, interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or is_monochrome(frame):\n",
    "            continue  # Skip the frame if it's not successfully read or is monochrome\n",
    "        extracted_frames.append(frame)\n",
    "        if len(extracted_frames) == target_frames:\n",
    "            break  # Stop if we have extracted the target number of frames\n",
    "    \n",
    "    # If not enough frames extracted, add white frames\n",
    "    # check if extracted_frames is empty. If so, use the video resolution to create a white frame.\n",
    "    if len(extracted_frames) < target_frames:\n",
    "        if extracted_frames:\n",
    "            white_frame = 255 * np.ones_like(extracted_frames[0])  # Assuming all frames are of the same dimension\n",
    "        else:\n",
    "            # If no frames were extracted, we need to get the video resolution to create a white frame\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                white_frame = 255 * np.ones_like(frame)\n",
    "            else:\n",
    "                # If we can't read a frame to get the resolution, we will default to 1080p (1920x1080)\n",
    "                white_frame = 255 * np.ones((1080, 1920, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Append white frames until we have 100 frames\n",
    "        while len(extracted_frames) < target_frames:\n",
    "            extracted_frames.append(white_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return extracted_frames\n",
    "\n",
    "# Define a function to save frames to disk\n",
    "def save_frames(frames, output_dir, video_name):\n",
    "    # Make sure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Save each frame to disk\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame_filename = f\"{video_name}_frame_{i:03d}.png\"\n",
    "        frame_path = os.path.join(output_dir, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "# Define the directory for non-hate videos\n",
    "non_hate_videos_dir = '../Datas/non_hate_videos'\n",
    "\n",
    "# Define the output directory for extracted frames\n",
    "output_frames_dir = '../Datas/extract_non_hate_frame'\n",
    "\n",
    "# List all non-hate videos\n",
    "non_hate_video_files = [f for f in os.listdir(non_hate_videos_dir) if f.endswith('.mp4')]\n",
    "\n",
    "# Process each non-hate video and save the frames\n",
    "for video_file in non_hate_video_files:\n",
    "    video_path = os.path.join(non_hate_videos_dir, video_file)\n",
    "    frames = extract_frames_from_non_hate_video(video_path)\n",
    "    save_frames(frames, output_frames_dir, video_file.split('.')[0])  # We use the video name without the extension\n",
    "\n",
    "# Let's print out a success message\n",
    "print(\"Finished extracting and saving frames for non-hate videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Load annotations\u001b[39;00m\n\u001b[1;32m     84\u001b[0m annotations_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Datas/HateMM_annotation.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 85\u001b[0m annotations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(annotations_path)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Process each hate video and save the frames based on annotations\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m annotations\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the function to convert a time string to a frame index\n",
    "def time_to_frame_index(time_str, fps):\n",
    "    \"\"\"\n",
    "    Convert a time string in the format HH:MM:SS to a frame index.\n",
    "    Args:\n",
    "    - time_str (str): Time string to convert.\n",
    "    - fps (float): Frames per second of the video.\n",
    "\n",
    "    Returns:\n",
    "    - int: Frame index corresponding to the given time.\n",
    "    \"\"\"\n",
    "    # Split the time string into hours, minutes, and seconds\n",
    "    h, m, s = map(int, time_str.split(':'))\n",
    "    # Calculate the frame index\n",
    "    frame_index = (h * 3600 + m * 60 + s) * fps\n",
    "    return int(frame_index)\n",
    "\n",
    "# Define the function to extract frames from hate videos based on annotations\n",
    "def extract_frames_from_hate_video(video_path, hate_intervals, target_frames=100):\n",
    "    # Get video info\n",
    "    total_frames, fps = get_video_info(video_path)\n",
    "    if total_frames is None:\n",
    "        return []  # If video info couldn't be retrieved, return an empty list\n",
    "    \n",
    "    # Calculate the frame indices from hate intervals\n",
    "    hate_frame_indices = []\n",
    "    for start_time, end_time in hate_intervals:\n",
    "        start_frame = time_to_frame_index(start_time, fps)\n",
    "        end_frame = time_to_frame_index(end_time, fps)\n",
    "        hate_frame_indices.extend(range(start_frame, min(end_frame, total_frames)))\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Initialize list to store frames\n",
    "    extracted_frames = []\n",
    "    \n",
    "    # Extract frames based on hate intervals\n",
    "    for idx in sorted(set(hate_frame_indices)):\n",
    "        if len(extracted_frames) == target_frames:\n",
    "            break  # Stop if we have extracted the target number of frames\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or is_monochrome(frame):\n",
    "            continue  # Skip the frame if it's not successfully read or is monochrome\n",
    "        extracted_frames.append(frame)\n",
    "    \n",
    "    # If not enough frames extracted, add remaining video frames or white frames\n",
    "    additional_frame_indices = [i for i in range(total_frames) if i not in hate_frame_indices]\n",
    "    np.random.shuffle(additional_frame_indices)  # Shuffle to get a random sampling of remaining frames\n",
    "    for idx in additional_frame_indices:\n",
    "        if len(extracted_frames) == target_frames:\n",
    "            break  # Stop if we have reached the target number of frames\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or is_monochrome(frame):\n",
    "            continue  # Skip the frame if it's not successfully read or is monochrome\n",
    "        extracted_frames.append(frame)\n",
    "    \n",
    "    # If still not enough frames, add white frames\n",
    "    if len(extracted_frames) < target_frames:\n",
    "        if extracted_frames:\n",
    "            white_frame = 255 * np.ones_like(extracted_frames[0])\n",
    "        else:\n",
    "            # If no frames were extracted, we need to get the video resolution to create a white frame\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                white_frame = 255 * np.ones_like(frame)\n",
    "            else:\n",
    "                # If we can't read a frame to get the resolution, we will default to 1080p (1920x1080)\n",
    "                white_frame = 255 * np.ones((1080, 1920, 3), dtype=np.uint8)\n",
    "        extracted_frames += [white_frame] * (target_frames - len(extracted_frames))\n",
    "    \n",
    "    cap.release()\n",
    "    return extracted_frames\n",
    "\n",
    "# Define the directory for hate videos\n",
    "hate_videos_dir = '../Datas/hate_videos'\n",
    "\n",
    "# Define the output directory for extracted hate frames\n",
    "output_hate_frames_dir = '../Datas/extract_hate_frame'\n",
    "# Load annotations\n",
    "annotations_path = '../Datas/HateMM_annotation.csv'\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "# Process each hate video and save the frames based on annotations\n",
    "for index, row in annotations.iterrows():\n",
    "    if row['label'] == 'Hate':\n",
    "        # Construct the video path\n",
    "        video_path = os.path.join(hate_videos_dir, row['video_file_name'])\n",
    "        \n",
    "        # Parse hate intervals from the annotation\n",
    "        hate_intervals = eval(row['hate_snippet'])\n",
    "        \n",
    "        # Extract frames from the hate video\n",
    "        frames = extract_frames_from_hate_video(video_path, hate_intervals)\n",
    "        \n",
    "        # Save the frames to disk\n",
    "        save_frames(frames, output_hate_frames_dir, row['video_file_name'].split('.')[0])\n",
    "\n",
    "# Let's print out a success message\n",
    "print(\"Finished extracting and saving frames for hate videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# 定义获取视频信息的函数\n",
    "def get_video_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return None, None\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    return total_frames, fps\n",
    "\n",
    "# 检测单色帧的函数\n",
    "def is_monochrome(frame: np.ndarray, threshold: int = 15) -> bool:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return np.std(gray_frame) < threshold\n",
    "\n",
    "# 从非仇恨视频中提取帧的函数\n",
    "def extract_frames_from_non_hate_video(video_path, target_frames=100):\n",
    "    total_frames, fps = get_video_info(video_path)\n",
    "    if total_frames is None:\n",
    "        return []\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    interval = max(1, total_frames // target_frames)\n",
    "    extracted_frames = []\n",
    "    \n",
    "    for i in range(0, total_frames, interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or is_monochrome(frame):\n",
    "            continue\n",
    "        extracted_frames.append(frame)\n",
    "        if len(extracted_frames) == target_frames:\n",
    "            break\n",
    "    \n",
    "    if len(extracted_frames) < target_frames:\n",
    "        if extracted_frames:\n",
    "            white_frame = 255 * np.ones_like(extracted_frames[0])\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            white_frame = 255 * np.ones_like(frame) if ret else 255 * np.ones((1080, 1920, 3), dtype=np.uint8)\n",
    "        while len(extracted_frames) < target_frames:\n",
    "            extracted_frames.append(white_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return extracted_frames\n",
    "\n",
    "# 保存帧到磁盘的函数\n",
    "def save_frames(frames, output_dir, video_name):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame_filename = f\"{video_name}_frame_{i:03d}.png\"\n",
    "        frame_path = os.path.join(output_dir, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "# 时间字符串转帧索引的函数\n",
    "def time_to_frame_index(time_str, fps):\n",
    "    h, m, s = map(int, time_str.split(':'))\n",
    "    frame_index = (h * 3600 + m * 60 + s) * fps\n",
    "    return int(frame_index)\n",
    "\n",
    "# 从仇恨视频中提取帧的函数\n",
    "def extract_frames_from_hate_video(video_path, hate_intervals, target_frames=100):\n",
    "    total_frames, fps = get_video_info(video_path)\n",
    "    if total_frames is None:\n",
    "        return []\n",
    "    \n",
    "    hate_frame_indices = []\n",
    "    for start_time, end_time in hate_intervals:\n",
    "        start_frame = time_to_frame_index(start_time, fps)\n",
    "        end_frame = time_to_frame_index(end_time, fps)\n",
    "        hate_frame_indices.extend(range(start_frame, min(end_frame, total_frames)))\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    extracted_frames = []\n",
    "    \n",
    "    for idx in sorted(set(hate_frame_indices)):\n",
    "        if len(extracted_frames) == target_frames:\n",
    "            break\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or is_monochrome(frame):\n",
    "            continue\n",
    "        extracted_frames.append(frame)\n",
    "    \n",
    "    additional_frame_indices = [i for i in range(total_frames) if i not in hate_frame_indices]\n",
    "    np.random.shuffle(additional_frame_indices)\n",
    "    for idx in additional_frame_indices:\n",
    "        if len(extracted_frames) == target_frames:\n",
    "            break\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or is_monochrome(frame):\n",
    "            continue\n",
    "        extracted_frames.append(frame)\n",
    "    \n",
    "    if len(extracted_frames) < target_frames:\n",
    "        if extracted_frames:\n",
    "            white_frame = 255 * np.ones_like(extracted_frames[0])\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            white_frame = 255 * np.ones_like(frame) if ret else 255 * np.ones((1080, 1920, 3), dtype=np.uint8)\n",
    "        while len(extracted_frames) < target_frames:\n",
    "            extracted_frames.append(white_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return extracted_frames\n",
    "\n",
    "# 目录路径\n",
    "hate_videos_dir = '../Datas/hate_videos'\n",
    "non_hate_videos_dir = '../Datas/non_hate_videos'\n",
    "output_frames_dir = '../Datas/extract_non_hate_frame'\n",
    "output_hate_frames_dir = '../Datas/extract_hate_frame'\n",
    "annotations_path = '../Datas/HateMM_annotation.csv'\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "\n",
    "# 提取非仇恨视频帧\n",
    "def process_non_hate_video(video_file):\n",
    "    video_path = os.path.join(non_hate_videos_dir, video_file)\n",
    "    frames = extract_frames_from_non_hate_video(video_path)\n",
    "    save_frames(frames, output_frames_dir, video_file.split('.')[0])\n",
    "    print(f\"Finished extracting and saving frames for non-hate video: {video_file}\")\n",
    "\n",
    "# 提取仇恨视频帧\n",
    "def process_hate_video(index, row):\n",
    "    if row['label'] == 'Hate':\n",
    "        video_path = os.path.join(hate_videos_dir, row['video_file_name'])\n",
    "        hate_intervals = eval(row['hate_snippet'])\n",
    "        frames = extract_frames_from_hate_video(video_path, hate_intervals)\n",
    "        save_frames(frames, output_hate_frames_dir, row['video_file_name'].split('.')[0])\n",
    "        print(f\"Finished extracting and saving frames for hate video: {row['video_file_name']}\")\n",
    "\n",
    "# 并行处理非仇恨视频\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    non_hate_video_files = [f for f in os.listdir(non_hate_videos_dir) if f.endswith('.mp4')]\n",
    "    executor.map(process_non_hate_video, non_hate_video_files)\n",
    "\n",
    "# 并行处理仇恨视频\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(process_hate_video, annotations.iterrows())\n",
    "\n",
    "print(\"Finished extracting and saving frames for all videos.\")\n",
    "# 主要改进点\n",
    "# 并行处理：使用 ThreadPoolExecutor 实现多线程并行处理，提高处理速度。\n",
    "# 错误处理：增加了对视频无法打开或无法读取帧的错误处理。\n",
    "# 代码重构：将重复的代码提取到函数中，提高代码的可读性和可维护性。\n",
    "# 日志记录：增加了打印日志信息，以便跟踪处理进度和错误。\n",
    "# 1. 统一帧数\n",
    "# 上采样：对帧数较少的视频，通过插值或重复帧来增加帧数。\n",
    "# 下采样：对帧数较多的视频，通过随机采样或固定间隔采样来减少帧数。\n",
    "# 2. 数据增强\n",
    "# 通过数据增强技术，生成更多样本来平衡数据集。以下是一些常见的数据增强技术：\n",
    "\n",
    "# 旋转：随机旋转帧图像。\n",
    "# 缩放：随机缩放帧图像。\n",
    "# 平移：随机平移帧图像。\n",
    "# 翻转：随机翻转帧图像。\n",
    "# 噪声：添加随机噪声。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video has 25.0 FPS, and 50 seconds is approximately 1250 frames.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def calculate_frames_for_duration(video_path, duration_in_seconds=50):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return None\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(duration_in_seconds * fps)\n",
    "    cap.release()\n",
    "    return total_frames, fps\n",
    "\n",
    "# 示例：计算50秒的视频帧数\n",
    "video_path = '../Datas/hate_videos/hate_video_2.mp4'\n",
    "frames, fps = calculate_frames_for_duration(video_path)\n",
    "if frames is not None:\n",
    "    print(f\"The video has {fps} FPS, and 50 seconds is approximately {frames} frames.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
